# Default values for example.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

replicaCount: 1

image:
  repository: nginx
  pullPolicy: IfNotPresent

imagePullSecrets: []
nameOverride: ""
fullnameOverride: ""

serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name:

podSecurityContext: {}
  # fsGroup: 2000

securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

service:
  type: ClusterIP
  port: 80

ingress:
  enabled: false
  annotations: {}
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
  hosts:
    - host: chart-example.local
      paths: []
  tls: []
  #  - secretName: chart-example-tls
  #    hosts:
  #      - chart-example.local

resources: {}
  # We usually recommend not to specify default resources and to leave this as a conscious
  # choice for the user. This also increases chances charts run on environments with little
  # resources, such as Minikube. If you do want to specify resources, uncomment the following
  # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
  # limits:
  #   cpu: 100m
  #   memory: 128Mi
  # requests:
  #   cpu: 100m
  #   memory: 128Mi

nodeSelector: {}

tolerations: []

affinity: {}

global:
  agtK8Config:
    # some cluster instances require resource-spec for the deployment, e.g. GE Digital
    # PCS CF1/CF3 Cluster, whereas some can simply ignore the usage.
    resources:
      limits:
        cpu: 200m
        memory: 1Gi
      requests:
        cpu: 200m
        memory: 512Mi
    svcPortNum: 18080
    svcHealthPortNum: 18081
    # options v1.1beta|v1|v1beta
    releaseTag: v1
    # replicaCount currently supports client instances only.
    # supporting scaling gateway/server instances in k8s is in discussion.
    replicaCount: 1
    # withIngress decides the availability of the agt ingress obj in deployment.
    # by default, when deploy as the gateway mode (conf.mod=gateway), the value (enabled) will be overridden to true
    withIngress:
      enabled: true
      # host utilised to make the agt accessible via non-tls traffic. 
      # it is also possible for the co-existence and the overlap of both tls/non-tls routings (hosts/tls)
      hosts:
        - host: ec.http.helloworld.ge.com
          paths: ["/agent", "/health", "/v1", "/v1beta"]
      # present if the agt is accessible via wss|https.
      # example empty array below indicates no tls assignment is avaialble 
      # tls: [] 
      tls:
        - secretName: tls-secret-1
          hosts: ["ec.helloworld.ge.com", "ec.rel.ge.com"]
        - secretName: tls.secret-2
          hosts: ["*.ec.https.ge.com", "ec.dev.azure.com"]
    # options below are applicable only in the agent+plugins helm package. 
    # this setting is intended to deploy a plugin alongside the agent when "-plg" is present or is "true"
    withPlugins:
      # the tls setting only valid when agent mode "-mod" is either "server" or "gw:server"
      tls:
        enabled: true
        schema: https 
        hostname: twitter.com
        tlsport: 443
        proxy: http://traffic-manipulation.job.security.io:8080
        port: 17990
      # the vln setting only valid when agent mode "-mod" is either "client" or "gw:client"
      vln:
        # The "enabled" keypair will be overridden by the "agtConfig" setting, if specified. E.g. "conf.vln=true"
        enabled: false
        # the "remote" keypair indicates the vlan deployment strategy. When default to true,
        # the vlan setup will ignore the "ips" setting, and instead simulate only the "ports"-
        # setting via a series of service/pod remote to the client application. In the remote-
        # scenario, it is subject to the client app's configuration in its respective pod in order-
        # to make the "ips" setting work correcly. Otherwise the setup will deploy the plugin artifact-
        # along with the ips/ports setting, and assume the direct interaction with the local loopback-
        # interface at the parental pod.
        remote: false
        # customise the securityContext when the vln plugin launched in a multi-contr pod (remote: false)
        securityContext:
          # defer the container runner as an guest user. E.g. uid: 4000
          runAsUser: 0
          # deny a potential privilege escalation request
          allowPrivilegeEscalation: false
          privileged: false
        # The "ports" keypair will be overridden by the default "agtConfig" setting, if specified. E.g. "conf.rpt=<port1,port2..portn>"
        ports: [8000,8001,8002,8003]
        # The "ips" keypair is ignored when set "remote" to true
        ips: ["10.10.10.0/30","8.8.8.100","8.8.8.101","8.8.8.102"]
